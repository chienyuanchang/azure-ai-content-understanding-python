{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure the Azure AI service is configured by following the [configuration steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Install the required packages to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a collection of analyzer templates designed to extract fields from different types of input files.\n",
    "\n",
    "These templates are highly customizable, allowing you to modify them to meet your specific requirements. For additional verified templates from Microsoft, please refer to [this directory](../analyzer_templates/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_templates = {\n",
    "    # Extract fields from invoices without grounding sources or confidence scores.\n",
    "    \"invoice\": ('../analyzer_templates/invoice.json', '../data/invoice.pdf'),\n",
    "\n",
    "    # Extract fields from invoices including grounding sources and confidence scores (optional).\n",
    "    \"invoice_field_source\": ('../analyzer_templates/invoice_field_source.json', '../data/invoice.pdf'),\n",
    "\n",
    "    # Extract insights from call recordings, such as summaries, topics, companies, and people mentioned.\n",
    "    \"call_recording\": ('../analyzer_templates/call_recording_analytics.json', '../data/callCenterRecording.mp3'),\n",
    "\n",
    "    # Extract summary and sentiment from conversational audio (e.g., customer service calls).\n",
    "    \"conversation_audio\": ('../analyzer_templates/conversational_audio_analytics.json', '../data/callCenterRecording.mp3'),\n",
    "\n",
    "    # Extract descriptions and perform sentiment analysis on marketing videos.\n",
    "    \"marketing_video\": ('../analyzer_templates/marketing_video.json', '../data/FlightSimulator.mp4'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the analyzer template you wish to use and assign a unique name for the analyzer that will be created based on this template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "ANALYZER_TEMPLATE = \"invoice\"\n",
    "\n",
    "(analyzer_template_path, analyzer_sample_file_path) = extraction_templates[ANALYZER_TEMPLATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class providing functions to interact with the Content Understanding API. Prior to the official release of the Content Understanding SDK, it serves as a lightweight SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Load environment variables from a .env file if present\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "\n",
    "# Add the parent directory to the system path to import shared modules\n",
    "parent_dir = Path.cwd().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "# Authenticate using DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Initialize the Content Understanding client\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_ENDPOINT,\n",
    "    api_version=AZURE_AI_API_VERSION,\n",
    "    token_provider=token_provider,\n",
    "    # Uncomment the following line to enable usage telemetry for this sample\n",
    "    # x_ms_useragent=\"azure-ai-content-understanding-python/field_extraction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Analyzer from the Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique analyzer ID\n",
    "CUSTOM_ANALYZER_ID = \"field-extraction-sample-\" + str(uuid.uuid4())\n",
    "\n",
    "# Begin creation of the analyzer using the selected template\n",
    "response = client.begin_create_analyzer(CUSTOM_ANALYZER_ID, analyzer_template_path=analyzer_template_path)\n",
    "\n",
    "# Poll the result until the creation operation completes\n",
    "result = client.poll_result(response)\n",
    "\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Fields Using the Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the analyzer is successfully created, you can use it to analyze your input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin analysis of the sample file using the created analyzer\n",
    "response = client.begin_analyze(CUSTOM_ANALYZER_ID, file_location=analyzer_sample_file_path)\n",
    "\n",
    "# Poll the result until the analysis operation completes\n",
    "result_json = client.poll_result(response)\n",
    "\n",
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "Optionally, delete the sample analyzer from your resource. Typically, you would analyze multiple files using the same analyzer without deleting it each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(CUSTOM_ANALYZER_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}